---
title: "Lab: Random Forest and Boosting"
author: "Akshay_Gupta_36-600_Lab_09R"
output: 
  html_document:
    toc: no
    toc_float: no
    theme: spacelab
---

# Regression

We import the heart-disease dataset and log-transform the response variable, `Cost`:
```{r}
df      <- read.csv("http://www.stat.cmu.edu/~pfreeman/heart_disease.csv",stringsAsFactors=TRUE)
df      <- df[,-10]
w       <- which(df$Cost > 0)
df      <- df[w,]
df$Cost <- log(df$Cost)
```

## Question 1

Split these data into training and test sets, reusing the random-number-generator seed you used in previous labs when analyzing these data.
```{r}
# REPLACE ME WITH CODE
set.seed(123)
train_index <- sample(nrow(df),round(0.7*nrow(df)))
df.train <- df[train_index, ]
df.test <- df[-train_index, ]
```

## Question 2

Learn a random forest model given the training data, and compute the MSE. Remember to set `importance=TRUE`. **Note: for reproducible results, set the seed before running random forest!** Assuming you split the data in the same manner as you did before, feel free to look back at your other labs and see if the MSE is smaller here. (For me and my split? It is...about 10% smaller than for a regression tree.)
```{r}
# REPLACE ME WITH CODE
# Load library
suppressMessages(library(randomForest))

# Fit a random forest model on the training data, setting importance to TRUE
rf.out <- randomForest(Cost ~ ., data = df.train, importance = TRUE)

# Predict on the test set
resp.pred <- predict(rf.out, newdata = df.test)

# Calculate the Mean Squared Error (MSE) on the test set
mse <- mean((resp.pred - df.test$Cost)^2)

# Print the MSE (MSE is smaller than tree model)
cat("Mean Squared Error (MSE) of the Random Forest model:", mse, "\n")
```

## Question 3

Create the variable importance plot. Remember to pass `type=1` as an argument to this plot. Mentally note the important variables. These should be consistent with those variables that appeared in your regression tree in the tree lab.
```{r fig.align='center',fig.height=4,fig.width=4}
# REPLACE ME WITH CODE
# Plot the variable importance with type=1
varImpPlot(rf.out, type=1, main="Variable Importance Plot (Random Forest)")
```

## Question 4

Show the diagnostic plot of predicted test-set response values vs. observed test-set response values. As usual, make sure the limits are the same along both axes and plot a diagonal line with slope 1.
```{r fig.align='center',fig.height=4,fig.width=4}
# REPLACE ME WITH CODE
# Load necessary library
suppressMessages(library(tidyverse))

# Generate the diagnostic plot using ggplot
ggplot(data = data.frame("x" = df.test$Cost,  # Observed values
                         "y" = resp.pred),   # Predicted values
       mapping = aes(x = x, y = y)) +
  geom_point(size = 1, color = "deepskyblue") +  # Scatter plot of predicted vs observed
  geom_abline(intercept = 0, slope = 1, color = "red") +  # Diagonal line with slope 1
  xlim(0, max(c(df.test$Cost, resp.pred))) +  # Set limits for x-axis
  ylim(0, max(c(df.test$Cost, resp.pred))) +  # Set limits for y-axis
  labs(title = "Predicted vs Observed Values",
       x = "Observed Values",
       y = "Predicted Values") +
  theme_minimal()  # Use a minimal theme for clean presentation
```

## Question 5

Now learn an extreme gradient boosting model, and show the test-set MSE. Note that in order to do this, we have to remove the variables `Gender`, `Drugs`, and `Complications`, which are factor or factor-like variables, and for ease of code implementation, we will break up `df.train` and `df.test` into predictor and response variables:
```{r}
df.train %>% dplyr::select(.,-Gender,-Drugs,-Complications) -> df.train
df.test  %>% dplyr::select(.,-Gender,-Drugs,-Complications) -> df.test
resp.train <- df.train[,1]
resp.test  <- df.test[,1]
pred.train <- df.train[,-1]
pred.test  <- df.test[,-1]
```
Note that by doing this, the MSE that we get might not be as good as for random forest. But we'll see!
```{r}
# REPLACE ME WITH CODE
suppressMessages(library(xgboost))

# Create DMatrix objects for training and test sets
train <- xgb.DMatrix(data = as.matrix(df.train[, -1]), label = df.train$Cost)
test <- xgb.DMatrix(data = as.matrix(df.test[, -1]), label = df.test$Cost)

# Train the model using cross-validation
xgb.cv.out <- xgb.cv(params = list(objective = "reg:squarederror"), train, nrounds = 30, nfold = 5, verbose = 0)

# Extract minimum RMSE and optimal number of trees

optimal_nrounds <- which.min(xgb.cv.out$evaluation_log$test_rmse_mean)
cat("The optimal number of trees is ", optimal_nrounds, "\n")

xgb.out <- xgboost(train,nrounds=optimal_nrounds,params=list(objective="reg:squarederror"),verbose=0)
resp.pred <- predict(xgb.out,newdata=test)

# Calculate the Mean Squared Error (MSE) on the test set
mse <- mean((resp.pred - df.test$Cost) ^ 2)  # Calculate MSE against the Cost variable
cat("Mean Squared Error (MSE) on the test set:", round(mse, 3), "\n")  # Print the MSE
```

## Question 6

Create a variable importance plot for the extreme gradient boosting model. Make a mental note about whether the variables identified as important here are also the more important ones identified by random forest.
```{r fig.align='center',fig.height=4,fig.width=4}
# REPLACE ME WITH CODE
imp.out <- xgb.importance(model = xgb.out)
xgb.plot.importance(importance_matrix = imp.out, col = "blue")
```

---

# Classification

We will now load in the data on political movements that you looked at in previous labs:
```{r}
load(url("http://www.stat.cmu.edu/~pfreeman/movement.Rdata"))
f <- function(variable,level0="NO",level1="YES") {
  n               <- length(variable)
  new.variable    <- rep(level0,n)
  w               <- which(variable==1)
  new.variable[w] <- level1
  return(factor(new.variable))
}
predictors$nonviol      <- f(predictors$nonviol)
predictors$sanctions    <- f(predictors$sanctions)
predictors$aid          <- f(predictors$aid)
predictors$support      <- f(predictors$support)
predictors$viol.repress <- f(predictors$viol.repress)
predictors$defect       <- f(predictors$defect)
levels(response)        <- c("FAILURE","SUCCESS")
df           <- cbind(predictors,response)
names(df)[9] <- "label"
rm(id.half,id,predictors.half,predictors,response)
```

Note that given the number of factor variables in this dataset, we'll forego learning a boosting model below.

## Question 7

Split the data! Recreate what you did for previous labs, including the random-number-generator seed.
```{r}
# REPLACE ME WITH CODE
set.seed(117)
train_index <- sample(nrow(df),round(0.7*nrow(df)))
df.train <- df[train_index,]
df.test  <- df[-train_index,]
```

## Question 8

Learn a random forest model. Output probabilities for Class 1 (see the notes!) but do not output a confusion matrix or output a misclassification rate. It will become clear why we will hold off on computing this quantities for now... However, having said all this, do go ahead and plot the variable importance plot here.
```{r fig.align='center',fig.height=4,fig.width=4}
# REPLACE ME WITH CODE
# Load necessary libraries
suppressMessages(library(randomForest))

# Learn the random forest model
rf.model <- randomForest(label ~ ., data = df.train, probability = TRUE)

# Output probabilities for Class 1
probabilities = predict(rf.model,newdata=df.test,type="prob")[,2]

# Extract variable importance values
importance_values <- importance(rf.model)

# Create a bar plot of variable importance
barplot(importance_values[order(importance_values[, "MeanDecreaseGini"], decreasing = FALSE), "MeanDecreaseGini"],
        names.arg = rownames(importance_values)[order(importance_values[, "MeanDecreaseGini"], decreasing = FALSE)],
        las = 1, 
        horiz = TRUE,
        col = "blue", 
        main = "Variable Importance Plot",
        xlab = "Mean Decrease Gini")
```

## Question 9

Plot a ROC curve for random forest, and output the AUC value.
```{r fig.align='center',fig.height=4,fig.width=4}
# REPLACE ME WITH CODE
suppressMessages(library(pROC))

# Create a ROC curve
roc_curve <- roc(df.test$label, probabilities)

# Plot ROC curve
plot(roc_curve, main = "ROC Curve for Random Forest", col = "blue", lwd = 2)

# Calculate and print AUC
auc_value <- auc(roc_curve)
legend("bottomright", legend = paste("AUC =", round(auc_value, 2)), box.lwd = 0)

# Print AUC value
print(paste("AUC value:", round(auc_value, 2)))
```

## Question 10

Use Youden's $J$ statistic to determine the optimal class-separation threshold. Output that number. Then, using that threshold, transform the test-set Class 1 probabilities to class predictions, and output the confusion matrix and the misclassification rate. (Note: you can reuse code from previous labs.)
```{r}
# REPLACE ME WITH CODE

cat("AUC for forest model: ",round(roc_curve$auc,3),"\n")

J <- roc_curve$sensitivities + roc_curve$specificities - 1
w <- which.max(J)
cat("Optimum threshold for forest model: ",round(roc_curve$thresholds[w],3),"\n")

# Transform probabilities to class predictions using the optimal threshold
optimal_threshold <- roc_curve$thresholds[w]
predictions <- ifelse(probabilities >= optimal_threshold, "SUCCESS", "FAILURE")

# Create a confusion matrix
confusion_matrix <- table(Predicted = predictions, Actual = df.test$label)

# Print confusion matrix
print(confusion_matrix)

# Calculate misclassification rate
misclassification_rate <- sum(predictions != df.test$label) / length(predictions)
cat("Misclassification rate:", round(misclassification_rate, 4), "\n")
```
